\section{How cmsearch and cmscan score alignments and determine significance}

The \prog{cmsearch} and \prog{cmscan} programs give you a ranked list
of hits in a sequence or CM database.  Which ones are likely to be
true homologs and which ones are likely to be nonhomologous to your
query CM?

Infernal gives you at least two scoring criteria to judge
by: the Infernal raw score, and an E-value. Additionally,
Rfam models carry a third set of criteria: three expert-calibrated raw
score cutoffs that the Rfam database curators set. How should you
interpret all this information?

\subsection{Executive summary}

\begin{itemize}

\item The best criterion of statistical significance is the E-value.
The E-value is calculated from the bit score. It tells you how many
false positives you would have expected to see at or above this bit
score. Therefore a low E-value is best; an E-value of 0.1, for
instance, means that there's only a 10\% chance that you would've seen
a hit this good in a target database of random sequences of the same
size as the one you're searching. {\em
Typically, I trust the results of searches at about E=0.01 and below,
and I examine the hits manually down to E=10 or so.}  However, be
alert; Infernal E-values are not perfect. 

\item Infernal bit scores are a stricter criterion: they reflect
whether the sequence is a better match to the profile model (positive
score) or to the null model of nonhomologous sequences (negative
score).  A bit score above $\log_2$ of the size of the target database
is likely to be a true homologue. For a 10 Mb genome, this
rule-of-thumb number is on the order of 24 bits (remember a 10 Mb
genome is really 20 Mb when you search both strands).  Whereas the
E-value measures how statistically significant the bit score is, the
bit score itself is telling you how well the sequence matches your
model. Because these things should be strongly correlated, usually,
true homologs will have both a good bit score and a good
E-value. However, sometimes (and these are the interesting cases), you
will find remote homologues which do not match the model well (and so
do not have good bit scores -- possibly even negative), but which
nonetheless have significant E-values, indicating that the bit score,
though ``bad'', is still better than you would've expected by chance,
so it is suggestive of homology. However, as above, be alert; it is
possible to get artifactually high bit scores simply because of highly
biased residue composition.
  
\item For Rfam CMs, you can also examine three other numbers that
  represent bit score thresholds: a TC (trusted cutoff) score, a GA
(gathering) score, and a NC (noise cutoff) score. The meaning of
these numbers is described below.
\end{itemize}

\begin{srefaq}{What does it mean when I have a negative bit score,
    but a good E-value?} The negative bit score means that the sequence is
  not a good match to the model. The good E-value means that it's still
  a better score than you would've expected from a random sequence. The
  usual interpretation is that the sequence is homologous to the
  sequence family modeled by the CM, but it's not ``within'' the family
  - it's a distant homologue of some sort. This happens most often with
  CMs built from ``tight'' families of high sequence identity, aligned
  to remote homologues outside the family. For example, a bacterial SRP
  CM aligned to a eukaryotic SRP may show this behavior - the bit
  score says the sequence isn't a bacterial SRP (correct) but the E-value says
  it is significantly related to the bacterial SRP family (also correct).
\end{srefaq}

\subsection{In more detail: Infernal bit scores}

The bit score is a log-odds score in log base two (thus, in units of
{\em bits}). Specifically, it is:

\[
S = \log_2 \frac {P( \mbox{seq} | \mbox{CM})} { P (\mbox{seq} |
  \mbox{null})}.
\]

$P( \mbox{seq} | \mbox{CM})$ is the probability of the target
sequence according to your CM. $ P (\mbox{seq} | \mbox{null}) $ is
the probability of the target sequence given a ``null hypothesis''
model of the statistics of random sequence. In Infernal, this null model
is a simple one-state CM that says that random sequences are i.i.d.
sequences with a specific residue composition, which by default is
equiprobable across the four RNA nucleotides ($P(A) = P(C) = P(G) =
P(U) = 0.25$). This ``null model distribution'' is part of the CM save
file, and it can be altered when you run \prog{cmbuild}.

Thus, a positive score means the CM is a better model of the target
sequence than the null model is (e.g. the CM gives a higher
probability).

You can specify the E-value or bit score cutoff to the \prog{cmsearch}
program. By default, for calibrated models (see below) the E-value
cutoff is set as 1.0, and for non-calibrated models (for which
E-values are not available) the cutoff is set as a bit score of 0.0
bits. (This is discussed in more detail in section 6). Alternatively,
for a specific sensible use cutoffs, read about how the Rfam
TC/NC/GA cutoffs are set and used (below).

\subsection{In more detail: Infernal E-values}

The E-value is the expected number of false positives with scores at
least as high as your hit.

Unlike the raw score, the E-value is dependent on the size of the
database you search. If \prog{cmsearch} detects a hit of length 100
residues with an E-value of 0.1 in a search of a sequence database of
size 100 Mb, then you happen to re-score the sequence all by itself
(i.e. create a new target sequence file that only contains the hit),
you will get an E-value 1 million times better. The E-value is quite
literally the expected number of false positives at this raw score;
the larger the database you search, the greater the number of expected
false positives.

\begin{srefaq}{Why do I get a different E-value when I search
against a file containing my sequence, than I got when I searched the
database?} See above. This behavior is shared with BLAST and FASTA
  P-value and E-values, so it should not be unfamiliar to most users.
  However, it can cause consternation: a related phenomenon is that a
hit that is marginally significant this year may no longer be
significant next year, when the database is twice as large. 
\end{srefaq}

For \prog{cmsearch} the database size is based on the number of
residues in the target sequence file. For \prog{cmscan} it is based on
the product of the number of residues in the query sequence and the number
of models in the target database. This difference is important to keep in mind
when comparing E-values between \prog{cmsearch} and \prog{cmscan}
output. Let's say you search a single query CM against a single
target sequence of length 1000 with \prog{cmsearch} and find a hit
with an E-value of 0.001. If you use \prog{cmscan} to search the same
sequence (now called the \emph{query} sequence) against the same
single CM (now called the \emph{target} CM) you will get the same
E-value for your hit. However, if you put your CM into a database with
99 other CMs, the E-value of your hit will increase 100-fold from
0.001 to 0.1 because now you're target CM database has grown
100-fold. However, the bit score of the hit will not
change.

To calculate E-values, models must be calibrated with the
\prog{cmcalibrate} program. Unfortunately, \prog{cmcalibrate} is
painfully slow. We're working on making it faster, but for now, it is
highly recommended that you spend the compute time to calibrate your
models before searching with them.  \prog{cmcalibrate} writes several
parameters into your CM file on lines with labels starting with
``E-''. Among these parameters are the $\mu$ (location) and $\lambda$
(scale) parameters of an exponential tail that best fits a histogram
of scores calculated on randomly generated sequences. You only need to
do this calibration once for a given CM. All the Rfam CMs come
pre-calibrated.

\begin{comment}
% This is no longer relevant with the filter pipeline
\subsubsection{\textsc{Warning:} Using negative bit score thresholds for local searches}
If the bit score threshold you use with local searches lower than
 $-5$,  you may begin to observe some strange
behavior. At a $-10$ bit threshold, \prog{cmsearch} will start to report
hits of a single residue in the target, that are clearly not
homologous sequences. This is because the local
alignment of a single residue to an average sized CM scores about $-10$
bits. In general, for local searches the lowest recommended bit score
cutoff is about $-5$ bits. If you commonly use
E-value cutoffs for local searches, be sure to check that the bit
score threshold that corresponds to your E-value cutoff is at least $-5$
bits. In practice this should only happen if you use a high E-value
cutoff for a small target database, for example an E-value cutoff of
$1000$ for a $1000$ nucleotide database. This issue is specific 
to local searches, and does not apply to glocal searches (enabled with the
 \prog{-g} option). 
\end{comment}

\subsection{In more detail: the CYK and Inside search algorithms in Infernal}
\prog{cmsearch} implements two different search algorithms, Inside and
CYK for profile SCFG search with CMs.  These algorithms differ in the
meaning of the score that they calculate. Above we oversimplified an
Infernal bit score as:
\[
	S = \log_2 \frac {P( \mbox{seq} | \mbox{CM})} { P (\mbox{seq} |
	\mbox{null})}.
\]

This is actually only correct for the Inside
algorithm. By CYK calculates something 
something slightly different in the \emph{numerator} (only) of the
above equation, as follows: 

\begin{wideitem}
\item[\em{Inside}]  $P(\mbox{seq}      | \mbox{CM})$
\item[\em{CYK}]     $P(\mbox{seq},\pi  | \mbox{CM})$
\end{wideitem}

Here, $\pi$ represents the optimal (most probable) parse, or
alignment, of the sequence to the model. So, CYK
reports the log-odds score for the optimal alignment 
of the sequence given the model, while
Inside reports the log odds score for the
sequence \emph{summed over all possible alignments} of the sequence to
the model. The CYK and Inside algorithms for SCFGs are analogous to
the HMM Viterbi and Forward algorithms, respectively.

From a probabilistic inference standpoint, the Inside 
score is giving us what we want to know, the log-odds score that the
sequence we're looking at is a homolog of the family we're
modelling. The specific alignment $\pi$ to the model is a nuisance
variable that is appropriately integrated out. Further, 
benchmarks show that Inside is more sensitive than CYK.
This is why Infernal search programs use Inside to define final bit
scores for all hits. CYK is used only as a part of the filter
pipeline. 
CYK makes a good filter for two reasons. First, it can be
more efficiently implemented than the Inside
algorithm. Infernal's current implementation of CYK is
about three times faster than Inside. Secondly,
high scoring CYK hits, the ones where interested in, tend to have a
single well-defined alignment and consequently approximate Inside
scores well. Combined, these two features mean we can safely and
effectively filter with CYK, and have the speed of CYK and sensitivity
of Inside. 
%You can read more about how CYK is used as a filter in \prog{cmsearch} in section 6.

\subsection{Accuracy of E-values}

The E-values reported by \prog{cmsearch} are not extremely accurate.
This is because CM scores don't fit the exponential tail distribution
extremely well. Empirically, local alignment scores returned from
local searches fit exponential tails fairly well, and glocal alignment
scores fit less well. We will continue to work on making E-values more
accurate in future versions of Infernal.

Certain types of sequences can lead to inaccurate E-values. For
example, inverted
tandem repeats often score high against any CM with a simple secondary
structure, especially those with a single stem loop (such as
miRNAs). This occurs because the often the repetitive stretches of residues
may look to Infernal as if they form Watson-Crick basepairs. 
More complex eukaryotic repeats actually derived from structural RNAs,
such as the Alu family from SRP RNA in human. In cases like this,
Infernal may recognize the homology in the repeat, even though the
element no longer functions as a structural RNA, giving a repeat a
high score and low E-value. Infernal would actually be right in this
situation since the homology is real, but users should be wary of this
situation when trying to annotate structural RNAs. 

An important factor in the accuracy of E-values is the GC content of
the target database. This is because many CMs are biased towards
particular GC content (usually low GC), in many cases giving A-rich
sequence high scores simply due to their high composition of
As. \prog{cmsearch} partially alleviates the problem of biased
composition using a post-hoc correction called null3 (see ``Biased
composition filtering: the null3 model below''). However, the problem
still persists and is particularly evident when the target database
being searched has a very low (about 25\%) or very high (about 65\%)
GC content. \prog{cmcalibrate} calibrates the E-value statistics for a
genome composition of about 46\% GC (based on an average measure from
a sampling of genomes from the three domains of life). When a target
database with GC content lower than 46\% is searched, the effect is
that there are usually more high scoring hits than the calibrated CM
expects, and lower E-values for random hits can result (that is you
might observe 5-25 hits with an E-value less than 1 for
example). Conversely, when a target database with GC content above
46\% is searched, the effect is the opposite, and higher E-values
often result (you might observe only 1-5 hits with an E-value less than
25). These effects are the average case, but different models will
give different results. 

We consider the E-values in Infernal a
work in progress, so feel free to report examples of particularly bad
(or good) performance of E-values to us.

\subsection{In more detail: Rfam TC/NC/GA cutoffs}

When a Rfam model is built, the Rfam curation team keeps track of
scores of every hit in a large nonredundant database. They record
three types of score cutoffs on Rfam CM files:

\begin{wideitem}
\item[GA (gathering cutoff)]: the score used as cutoff in
constructing Rfam. All database hits that score at or above the 
GA bit score will be included in the Rfam ``full alignment''.

\item[TC (trusted cutoff)]: the scores of the lowest-scoring hit(s)
that were included as true member(s) of the Rfam family. Hits above
the TC score are ``within'' the Rfam family and almost certainly
members.

\item[NC (noise cutoff)]: the score of the highest-scoring hit(s) that
were \textit{not} included as true members of the Rfam family, because
they were considered to be the top of the noise.  Hits above the NC
cutoff are above the top scoring noise in the Rfam NR database search,
so are likely homologues, but not as trustworthy as hits over the GA
or TC cutoffs.
\end{wideitem}

In order of increasing conservativeness, the cutoffs rank: NC, GA, and
TC.

The GA cutoff, being the actual cutoff used in constructing Rfam,
are a very good choice to use to collate large-scale automated data,
like counting RNA family members in a sequenced genome.

The TC and NC cutoffs are less useful, and only really there as
documentation of Rfam construction. In general, the TC cutoff would
be a extremely conservative cutoff to use in a database search, more
conservative than GA. The NC cutoff is less conservative than GA.

Why use GA (or the other cutoffs) instead of the E-value? Rfam
artificially imposes a ``flat'', nonhierarchical structure on RNA
sequence space.  Rfam asserts that no Rfam family is related to any
other Rfam family. This is obvious nonsense: many Rfam families are in
fact homologous.  The different SRP families are one example; the
different RNaseP families are another. Infernal often
detect significant relationships between families that Rfam chooses to
suppress. In these cases, the Rfam GA cutoff will be elevated to
artifically separate two homologous but distantly related subgroups of
the same structural superfamily.

\begin{srefaq}{Why isn't sequence X included in a Rfam full alignment?
It has a significant score!} For the reasons above, the sequences in
Rfam full alignments are harvested using curated GA thresholds, rather
than using score or E-value thresholds. Please don't go writing a
paper that claims CMs don't detect some similarity until you've done
the experiment with CMs (and E-values) instead of just looking at
curated Rfam classifications.
\end{srefaq}

The mechanism that Infernal uses to incorporate up these cutoffs is
general: Stockholm format multiple sequence alignments can carry
appropriate TC, NC, and GA markup lines. This means that you can use a
Rfam-like cutoff system if you like, just by adding the appropriate
Stockholm markup to your collection of alignments. When these numbers
are available in the CM, \prog{cmsearch} provides options
for setting search cutoffs to GA, TC, or NC automatically (these options
are \prog{--ga, --tc} and \prog{--nc}).

\subsubsection{Predicting running times for searches with Rfam cutoffs}
The next section explains how \prog{cmcalibrate} determines HMM filter
thresholds to use to accelerate \prog{cmsearch}. These filter
thresholds are dependent on the final threshold used in
\prog{cmsearch}, in general, the stricter the final threshold the
stricter the filter threshold and the greater the acceleration from
the filter. Because the Rfam GA/NC/TC cutoffs are relatively strict it
is often possible to achieve large speedups of up to 100-fold or more
when they're used as the final threshold. Section 6 explains this in
more detail, and shows an example of predicting the running time of
filtered searches with Rfam cutoffs using the \prog{cmstat} program.

\subsection{Biased composition filtering: the null3 model}

I've lied. Infernal bit scores are actually calculated as
log odds scores relative to \emph{two} null hypotheses. The first is the null model
built into the CM when it was built with \prog{cmbuild}.
The second, called \emph{null3}, is an \emph{ad hoc} model calculated
on the fly for each alignment, from the characteristics of that
alignment. (Why null3? To differentiate it from the null2 model used
by the \software{HMMER} software package). The purpose of null3 is to
compensate for false positive hits caused by simple biased composition
regions in the target sequence.

Common biased composition filters like XNU, DUST, and SEG are
qualitative filters -- if a region is detected as biased composition,
it is masked (the residues are converted to X's).  The
Infernal composition filter is a quantitative filter, that
tests whether the sequence is a better match to the CM, the
null (random composition) model, or a null3 model of biased nucleotide
composition.

This is a Good Thing, but on the other hand, the null3 model is not
very sophisticated. It is a single-state HMM just like the main null
model, which means it only captures residue composition, like DUST; no
attempt is made in Infernal to filter short-period repetitive sequences
like the XNU algorithm does. 

The null3 model was motivated by the observation that many
high-scoring false positive hits in \prog{cmsearch} are to regions of
the target database with with highly biased residue composition, in
particular regions with high percentages of A and U residues. The
first null model used by Infernal is by default 25\% A, C,
G, and U (this model can be changed with the \prog{--null} option to
\prog{cmbuild}). If a model has a bias for a particular residue, for
example A, and a target region is composed of an overrepresentation
of that residue then it will receive a high score simply because it is
A-rich. 

A different null3 model is calculated for every alignment. The 4
emission probabilities of the null3 model are calculated as 
simply their occurence within the region of the hit. For example, if
the hit is 50 residues long and contains $20$ As, $5$ Cs, $5$ Gs and $20$ Us,
then the null3 model probabilitiles will be calculated as $(0.4, 0.1,
0.1, 0.4)$. 

But now we've got \emph{two} null hypotheses. We said we report a bit
score that's a log-odds ratio of our model likelihood and \emph{one}
null hypothesis likelihood. How do we calculate a score if we have
more than one null hypothesis? Infernal does a bit of algebraic sleight
of hand here, to arrive at an additive correction to the original
score that it calls the ``null3 score correction''. 

\subsubsection{derivation of the null3 score correction}

We arrived at the parameters of the null3 model in a very \emph{ad
hoc} way. However, after that, the way Infernal arrives at the final bit
score once the null3 parameters have been determined is clean
(e.g. derivable) Bayesian probability theory. It is analagous to the
way \software{HMMER} uses the \emph{null2} score correction.

If we take the Bayesian view, we're interested in the probability of a
hypothesis $H$ given some observed data $D$:

\[
   P(H | D) = \frac{P(D | H) P(H)}{\sum_{H_i} P(D | H_i) P(H_i)},
\]

an equation which forces us to state explicit probabilistic models not
just for the hypothesis we want to test, but also for the alternative
hypotheses we want to test against. Up until now, we've considered two
hypotheses for an observed sequence $D$: either it came from our
CM (call that model $M$), or it came from our null hypothesis
for random, unrelated sequences (call that model $N$). If these are
the only two models we consider, the Bayesian posterior for the model
$M$ is:

\[
   P(M | D) = \frac{P(D | M) P(M)}{P(D | M) P(M) + P(D | N) P(N)}
\]

Recall that the log odds score (in units of bits) reported by
Infernal's alignment algorithms is

\[
  s = \log_2 \frac{P(D | M)}{P(D | N)}.
\]

Let's assume for simplicity that \emph{a priori}, the profile and the
null model are equiprobable, so the priors $P(M)$ and $P(N)$
cancel. Then the log odds score $s$ is related to the Bayesian
posterior by a sigmoid function,

\[
  P(M | D) = \frac{2^s}{2^s + 1}.
\]

(We don't have to assume that the two hypotheses are equiprobable;
keeping these around would just add an extra $\pi = \log P(M) / P(N)$
factor to $s$. We'll reintroduce these prior log odds scores $\pi$
shortly.)

The simple sigmoid relationship between the posterior and the log odds
score suggests a plausible basis for calculating a score that includes
contributions of more than one null hypothesis: \textbf{we desire a
generalized score $S$ such that:}

\[
  \frac{2^S}{2^S + 1} = P(M | D),
\]

\textbf{for \emph{any} number of alternative hypotheses under consideration.}

So, let $N_i$ represent any number of alternative null models
$N_i$. Then, by algebraic rearrangement of Bayes' theorem,

\[
   S = \log \frac{P(D | M) P(M)}{ \sum_{i} P(D | N_i) P(N_i)}. 
\]

We saw above that Infernal internally calculates a log odds score $s$, of
the model relative to the first null hypothesis. Let's now call that
$s_M$, the alignment score of the model. Infernal extends that same
scoring system to all additional competing hypotheses, calculating a
log odds score relative to the first null hypothesis for any
additional null hypotheses $i > 1$:

\[
  s_i = \log \frac{P(D | N_i)}{P(D | N_1)}
\]

We can also state prior scores $\pi_i$ for how relatively likely
each null hypothesis is, relative to the main one:

\[
  \pi_i = \log \frac{P(N_i)}{P(N_1)}
\]

(Remember that we assumed $\pi_M = 0$; but we're going to put it back
in anyway now.)

Now we can express $S$ in terms of the internal scores $s$ and
prior scores $\pi$:

\[
   S = \log  \frac{e^{s_M + \pi_M}} { 1 + \sum_{i>1} e^{s_i + \pi_i}},
\]

which therefore simply amounts to an additive correction of the
original score, $(s_M + \pi_M)$:

\[
  S = (s_M + \pi_M) - \log \left( 1 + \sum_{i>1} e^{s_i + \pi_i} \right)
\]

So, to calculate its reported score, Infernal uses four quantities:

\begin{enumerate}
\item [$s_M$] The (simple, uncorrected) log odds score for the model,
calculated by optimal alignment of the model to the sequence.

\item [$\pi_M$] The log odds of the priors, $\log P(M)/P(N_1)$. Infernal
   implicitly assumes this factor to be 0.

\item [$s_2$] The (simple, uncorrected) log odds score
   for the null3 hypothesis, calculated by rescoring the residues
   of the alignment under the null3 model.

\item [$\pi_2$] The log odds of the priors, $\log P(N_2)/P(N_1)$. 
Infernal arbitrarily assumes that the null3 model is
$\frac{1}{65536}$ as likely as the main null model, so this factor
is -16 bits.\footnote{In versions 1.0 through 1.0.2, the null3 model
  was assumed to be $\frac{1}{32}$ as likely as the main null model
  (-5 bit factor instead of -16 bits). The decreased value in version
  1.1 means that null3 penalties are reduced. We decided to do this
  based on internal benchmarking results. Version 1.1 uses a new
  default prior for parameterizing models which apparently alleviates
  the problem of biased composition, thus allowing us to reduce this
  value without sacrificing performance.}
\end{enumerate}

The code that calculates the null3 correction is in 
\prog{cm\_parsetree.c:ScoreCorrectionNull3()}.

The null3 correction is usually close to zero, for random sequences,
but becomes a significant quantitative penalty on biased composition
sequences.  It gets added to the original alignment score to form
Infernal's final bit score.

The null3 score correction is introduced in version 1.0 and was not
present in any of the 0.x versions of Infernal. This can
lead to large differences in the scores reported by 1.0 and previous
versions. 

The following table shows the penalty for a $100$ nucleotide hit with
varying compositions of A, C, G, and U residues. This table is included to give you
an idea of how severe the null3 correction is, and can be useful for
comparing bit scores from Infernal 1.0 to previous
versions (which did not use the null3 correction). These are just a
sample of the possible composition of hits you might see. Again, these
scores are for $100$ nucleotide hits, to determine the correction for
a hit of length $x$ simply multiply the corresponding correction below
by $x/100$. For example, a $35$\% A, $15$\% C, $15$\% G, $35$\% U hit
of length $100$ nt would receive a $6.88$ bit penalty from
null3 (row 4). A $200$ nt hit of the same composition would
receive a penalty of $13.76$ bits. A $50$ nt hit of the same
composition would receive a $3.44$ bit penalty.

\vspace{0.5in}

\begin{center}
\begin{tabular}{r|rrrr|c}
      &        &        &        &        & NULL3 \\ 
  GC\%&    A\% &   C\%  &   G\%  &    U\% & correction (bits)  \\ \hline
  0.0 &   50.0 &    0.0 &    0.0 &   50.0 &              95.00 \\
 10.0 &   45.0 &    5.0 &    5.0 &   45.0 &              48.10 \\
 20.0 &   40.0 &   10.0 &   10.0 &   40.0 &              22.81 \\
 30.0 &   35.0 &   15.0 &   15.0 &   35.0 &               6.88 \\
 35.0 &   32.5 &   17.5 &   17.5 &   32.5 &               2.01 \\
 40.0 &   30.0 &   20.0 &   20.0 &   30.0 &               0.30 \\
 45.0 &   27.5 &   22.5 &   22.5 &   27.5 &               0.07 \\
 50.0 &   25.0 &   25.0 &   25.0 &   25.0 &               0.04 \\
 55.0 &   22.5 &   27.5 &   27.5 &   22.5 &               0.07 \\
 60.0 &   20.0 &   30.0 &   30.0 &   20.0 &               0.30 \\
 65.0 &   17.5 &   32.5 &   32.5 &   17.5 &               2.01 \\
 70.0 &   15.0 &   35.0 &   35.0 &   15.0 &               6.88 \\
 80.0 &   10.0 &   40.0 &   40.0 &   10.0 &              22.81 \\
 90.0 &    5.0 &   45.0 &   45.0 &    5.0 &              48.10 \\
100.0 &    0.0 &   50.0 &   50.0 &    0.0 &              95.00 \\

\end{tabular}
\end{center}

\vspace{0.5in}


% obtained using esl-null3 a specialized easel miniapp
% created basically solely to make this table. 
% A frozen copy of the version used to make this table
% (with -l option)  
% is: /groups/eddy/home/nawrockie/notebook/12_0503_inf_tutorial/wd-infernal/easel/miniapps/bkups/12_0605-1/
%
% raw output:
% > esl-null3 -l 
%   GC      A      C      G      U  correction (bits)
%-----  -----  -----  -----  -----  -----------------
%100.0    0.0   50.0   50.0    0.0           84.00000
% 90.0    5.0   45.0   45.0    5.0           37.10043
% 80.0   10.0   40.0   40.0   10.0           11.80760
% 70.0   15.0   35.0   35.0   15.0            0.08019
% 65.0   17.5   32.5   32.5   17.5            0.00213
% 60.0   20.0   30.0   30.0   20.0            0.00016
% 55.0   22.5   27.5   27.5   22.5            0.00004
% 50.0   25.0   25.0   25.0   25.0            0.00002
% 45.0   27.5   22.5   22.5   27.5            0.00004
% 40.0   30.0   20.0   20.0   30.0            0.00016
% 35.0   32.5   17.5   17.5   32.5            0.00213
% 30.0   35.0   15.0   15.0   35.0            0.08019
% 20.0   40.0   10.0   10.0   40.0           11.80759
% 10.0   45.0    5.0    5.0   45.0           37.10044
%  0.0   50.0    0.0    0.0   50.0           84.00000

By default, the null3 score correction is used by \prog{cmcalibrate,
cmsearch} and \prog{cmscan}. It can be turned off in any of these
programs by using the \prog{--nonull3} option. However, be careful,
the E-values for models that are calibrated with \prog{--nonull3} are
only valid when \prog{--nonull3} is also used with \prog{cmsearch} or
\prog{cmscan}. Likewise, if \prog{--nonull3} is \emph{not} used during
calibration, it should not be used during searches or scans.


