\section{How \texttt{cmsearch} scores alignments and determines significance}

The \prog{cmsearch} program gives you a ranked list of hits in a
sequence database.  Which ones are likely to be true homologues and
which ones are likely to be nonhomologous to your query CM?

\software{infernal} gives you at least two scoring criteria to judge
by: the \software{infernal} raw score, and an E-value. Additionally,
Rfam models carry a third set of criteria: three expert-calibrated raw
score cutoffs that the Rfam database maintainers set. How should you
interpret all this information?

\subsection{Executive summary}

\begin{itemize}
\item The best criterion of statistical significance is the E-value.
The E-value is calculated from the bit score. It tells you how many
false positives you would have expected to see at or above this bit
score. Therefore a low E-value is best; an E-value of 0.1, for
instance, means that there's only a 10\% chance that you would've seen
a hit this good in a target database of random sequences of the same
size as the one you're searching. {\em
Typically, I trust the results of searches at about E=0.1 and below,
and I examine the hits manually down to E=10 or so.}  However, be
alert; \software{infernal} E-values are not perfect. 

\item \software{infernal} bit scores are a stricter criterion: they
  reflect whether the sequence is a better match to the profile model
  (positive score) or to the null model of nonhomologous sequences
  (negative score).  A bit score above $\log_2$ of the size of the
  target database is likely to be a true
  homologue. For a 10 Mb genome, this rule-of-thumb number is on
  the order of 24 bits (remember a 10 Mb genome is really 20 Mb when
  you search both strands).  Whereas the E-value measures how
  statistically significant the bit score is, the bit score itself is
  telling you how well the sequence matches your model. Because these
  things should be strongly correlated, usually, true homologues will
  have both a good bit score and a good E-value. However, sometimes
  (and these are the interesting cases), you will find remote
  homologues which do not match the model well (and so do not have
  good bit scores -- possibly even negative), but which nonetheless
  have significant E-values, indicating that the bit score, though
  ``bad'', is still better than you would've expected by chance, so it
  is suggestive of homology. However, as above, be alert; it is
  possible to get artifactually high bit scores simply because of
  highly biased residue composition.
  
\item For Rfam CMs, you can also examine three other numbers that
  represent bit score thresholds: a TC (trusted cutoff) score, a GA
(gathering) score, and a NC (noise cutoff) score. The meaning of
these numbers is described below.
\end{itemize}

\begin{srefaq}{What does it mean when I have a negative bit score,
    but a good E-value?} The negative bit score means that the sequence is
  not a good match to the model. The good E-value means that it's still
  a better score than you would've expected from a random sequence. The
  usual interpretation is that the sequence is homologous to the
  sequence family modeled by the CM, but it's not ``within'' the family
  - it's a distant homologue of some sort. This happens most often with
  CMs built from ``tight'' families of high sequence identity, aligned
  to remote homologues outside the family. For example, a bacterial SRP
  CM aligned to a eukaryotic SRP may show this behavior - the bit
  score says the sequence isn't a bacterial SRP (correct) but the E-value says
  it is significantly related to the bacterial SRP family (also correct).
\end{srefaq}

\subsection{In more detail: \software{infernal} bit scores}

The bit score is a log-odds score in log base two (thus, in units of
{\em bits}). Specifically, it is:

\[
S = \log_2 \frac {P( \mbox{seq} | \mbox{CM})} { P (\mbox{seq} |
  \mbox{null})}.
\]

$P( \mbox{seq} | \mbox{CM})$ is the probability of the target
sequence according to your CM. $ P (\mbox{seq} | \mbox{null}) $ is
the probability of the target sequence given a ``null hypothesis''
model of the statistics of random sequence. In \software{infernal}, this null model
is a simple one-state CM that says that random sequences are i.i.d.
sequences with a specific residue composition, which by default is
equiprobable across the four RNA nucleotides ($P(A) = P(C) = P(G) =
P(U) = 0.25$). This ``null model distribution'' is part of the CM save
file, and it can be altered when you run \prog{cmbuild}.

Thus, a positive score means the CM is a better model of the target
sequence than the null model is (e.g. the CM gives a higher
probability).

You can specify the E-value or bit score cutoff to the \prog{cmsearch}
program. By default, for calibrated models (see below) the E-value
cutoff is set as 1.0, and for non-calibrated models (for which
E-values are not available) the cutoff is set as a bit score of 0.0
bits. (This is discussed in more detail in section 6). Alternatively,
for a specific sensible use cutoffs, read about how the Rfam
TC/NC/GA cutoffs are set and used (below).

\subsection{In more detail: \software{infernal} E-values}

The E-value is the expected number of false positives with scores at
least as high as your hit.

Unlike the raw score, the E-value is dependent on the size of the
database you search. If you detect a hit of length 100 residues 
with an E-value of 0.1 in a search of a sequence database of size 100
Mb, then you happen to re-score the sequence all by itself, you will
get an E-value 1 million times better. The E-value is quite literally
the expected number of false positives at this raw score; the larger
the database you search, the greater the number of expected false
positives.

\begin{srefaq}{Why do I get a different E-value when I search
against a file containing my sequence, than I got when I searched the
database?} See above. This behavior is shared with BLAST and FASTA
  P-value and E-values, so it should not be unfamiliar to most users.
  However, it can cause consternation: a related phenomenon is that a
hit that is marginally significant this year may no longer be
significant next year, when the database is twice as large. 
\end{srefaq}

To calculate E-values, models must be calibrated with the
\prog{cmcalibrate} program. Unfortunately, \prog{cmcalibrate} is
painfully slow. We're working on making it faster, but for now, it is
highly recommended that you spend the compute time to calibrate your
models before searching with them. Not only will calibrated models
report E-values, but they are often much faster at searching. This is
because, in addition to calibrating E-value statistics, \prog{cmcalibrate}
also determines appropriate HMM filter cutoffs to use for each model, as
explained in section 6.

\prog{cmcalibrate} writes several parameters into your CM file on
lines with labels starting with ``E-''. Among these parameters are the
$\mu$ (location) and $\lambda$ (scale) parameters of an exponential
tail that best fits a histogram of scores calculated on randomly
generated sequences. You only need to do this calibration once
for a given CM. All the Rfam CMs come pre-calibrated.

\subsubsection{\textsc{Warning:} Using negative bit score thresholds for local searches}
If the bit score threshold you use with local searches lower than
 $-5$,  you may begin to observe some strange
behavior. At a $-10$ bit threshold, \prog{cmsearch} will start to report
hits of a single residue in the target, that are clearly not
homologous sequences. This is because the local
alignment of a single residue to an average sized CM scores about $-10$
bits. In general, for local searches the lowest recommended bit score
cutoff is about $-5$ bits. If you commonly use
E-value cutoffs for local searches, be sure to check that the bit
score threshold that corresponds to your E-value cutoff is at least $-5$
bits. In practice this should only happen if you use a high E-value
cutoff for a small target database, for example an E-value cutoff of
$1000$ for a $1000$ nucleotide database. This issue is specific 
to local searches, and does not apply to glocal searches (enabled with the
 \prog{-g} option). 

\subsubsection{fitting exponential tails to \software{infernal} score histograms}

The \prog{cmcalibrate} program fits exponential tails to scores of the
model against random sequences. When \prog{cmsearch} is run and hits
are found, the exponential tail parameters are used to calculate
E-value for the hits. \prog{cmsearch} implements different search
algorithms and allows searching with both local and glocally
configured models. Importantly, the configuration and algorithm used
affect the scores reported, so \prog{cmcalibrate} must fit separate
exponential tails for each.  In total,
\prog{cmcalibrate} fits 8 different exponential tail
distributions. These are listed by the program as it proceeds through
each of the 8 stages.  Because \prog{cmcalibrate} is so slow, it
has a \prog{--forecast} option which will list each stage and predict
it's required running time. Let's examine the output with this option
for the \prog{my.cm} model from the tutorial:

\user{cmcalibrate --forecast 1 my.cm}\\

\begin{sreoutput}
# Forecasting time for 1 processor(s) to calibrate CM 1: trna.5-1
#
# stage     mod  cfg  alg  expL (Mb)   filN predicted time
# --------  ---  ---  ---  --------- ------ --------------
  exp tail  hmm  glc  vit      15.00      -       00:02:29
  exp tail  hmm  glc  fwd      15.00      -       00:04:44
  exp tail   cm  glc  cyk       1.50      -       00:07:25
  exp tail   cm  glc  ins       1.50      -       00:23:34
  filter      -  glc    -          -  10000       00:02:22
  exp tail  hmm  loc  vit      15.00      -       00:02:45
  exp tail  hmm  loc  fwd      15.00      -       00:05:44
  exp tail   cm  loc  cyk       1.50      -       00:06:43
  exp tail   cm  loc  ins       1.50      -       00:23:32
  filter      -  loc    -          -  10000       00:06:24
# --------  ---  ---  ---  ---------  ----- --------------
# all         -    -    -          -      -       01:25:47
\end{sreoutput}


Let's go through what each column of the output is telling us:

\begin{wideitem}
\item[\emprog{stage}] 
  what type of stage this row pertains to, either
  ``exp tail'' for exponential tail fitting, or ``filter'' for filter
  threshold calculation. For now we're just focusing on the exponential tail
  stages. 

\item[\emprog{mod}] 
  the model we're fitting an exponential tail for,
  either the CM or a CP9 HMM. We use the HMM exponential tails during
  HMM filtering for faster searches.
  
\item[\emprog{cfg}] 
  the configuration of the model for this stage,
  either ``glc'' for glocal or ``loc'' for local. \prog{cmcalibrate}
  has to calibrate exponential tails \emph{separately} for glocal and
  local modes.

\item[\emprog{alg}] 
  the search algorithm for this stage. There are two
  algorithms that need to be separately calibrated for each the CM and
  HMM. These are explained in more detail in section 6.

\item[\emprog{expL}] 
  the length of random sequence we'll search for
  this stage. For CM stages, this length is 1,500,000 residues (1.5 Mb)
  by default. For HMM stages, this length is is the minimum
  of 15 Mb and a length $x$, where $x$ is the length that will cause
  this HMM stage to require 10\% as much compute time as a CM
  calibration stage. The reasoning behind this is that longer sequence
  lengths tend to result in more accurate E-values.
  %  Mb, but can be more if the program calculates that searching a
%  longer sequence with the HMM (which will lead to more accurate
%  E-values) will not increase the calibration time of this stage to more
%  than 10\% the total calibration time.

\item[\emprog{filN}] 
  the number of random sequences that will be
  searched for the HMM filter threshold calculation. This isn't
  relevant now; see section 6 for more on HMM filter threshold
  calculation. 

\item[\emprog{predicted time}] 
  the predicted run time of this stage. 

\end{wideitem}


As you can see, \prog{cmcalibrate} will fit separate exponential tails
for each combination of model and algorithm (4 choices) and configuration
(2 choices) that's $4*2=8$ exponential
tails. We explained the difference between local versus glocal
configuration in the tutorial, now we'll discuss different search algorithms. 

\subsection{In more detail: different search algorithms in \software{infernal}}
\prog{cmsearch} implements four several different search 
algorithms, Inside and CYK for profile SCFG search with CMs, and
Forward and Viterbi for profile HMM search with CP9 HMMs.
These algorithms
differ in the meaning of the score that they calculate. Above we
oversimplified an \software{infernal} bit score as:
\[
	S = \log_2 \frac {P( \mbox{seq} | \mbox{CM})} { P (\mbox{seq} |
	\mbox{null})}.
\]

This is actually only correct for the Inside
algorithm. The other three algorithms listed above are calculating
something slightly different in the \emph{numerator} (only) of the
above equation, as follows: 

\begin{wideitem}
\item[\em{Inside}]  $P(\mbox{seq}      | \mbox{CM})$
\item[\em{CYK}]     $P(\mbox{seq},\pi  | \mbox{CM})$
\item[\em{Forward}] $P(\mbox{seq}      | \mbox{HMM})$
\item[\em{Viterbi}] $P(\mbox{seq},\pi  | \mbox{HMM})$
\end{wideitem}

Here, $\pi$ represents the optimal (most probable) parse, or
alignment, of the sequence to the model. So, the CYK and Viterbi
algorithms report the log-odds score for the optimal alignment 
of the sequence given the model (either CM or HMM respectively), while
the Inside and Forward algorithms report the log odds score for the
sequence \emph{summed over all possible alignments} of the sequence to
the model. 

From a probabilistic inference standpoint, the Inside and Forward
scores are giving us what we want to know, the log-odds score that the
sequence we're looking at is a homolog of the family we're
modelling. The specific alignment $\pi$ to the model is a nuisance
variable that is appropriately integrated out. Not only are Inside and
Forward better in theory, but empirically, benchmarks show that
they're more sensitive than CYK and Viterbi. So, why use CYK and
Viterbi at all?  Actually, we rarely use Viterbi really, it's
only implemented for testing purposes (it's okay; calibrating Viterbi
E-values takes a very small fraction of the running time of
\prog{cmcalibrate}, you can see for yourself in the previous
example). CYK \emph{is} used, but mainly as a filter in
\prog{cmsearch}. CYK makes a good filter for two reasons. First, it can be
more efficiently implemented than the Inside
algorithm. \software{infernal}'s current implementation of CYK is
about three times faster than Inside (you can see this in the
predicted run times in the \prog{--forecast} example). Secondly,
high scoring CYK hits, the ones where interested in, tend to have a
single well-defined alignment and consequently approximate Inside
scores well. Combined, these two features mean we can safely and
effectively filter with CYK, and have the speed of CYK and sensitivity
of Inside. You can read more about how we use CYK as a filter in
\prog{cmsearch} in section 6.


\begin{srefaq}{Why are you talking about HMM algorithms. I thought CMs
    were more appropriate for structural RNA sequence analysis than
    HMMs, isn't that the whole reason you've developed \textsc{infernal}?} 
  We've implemented HMMs in \textsc{infernal} to help accelerate CM
    algorithms. As described in section 6, HMMs are used as filters to
    speedup database searches with \prog{cmsearch}. They're also used to develop
    constraints for CM alignment with \prog{cmalign}.  
\end{srefaq}

%This is the main reason \prog{cmcalibrate} is taking so
%long. Trust us, we'd love to be able to cut down on these stages and
%accelerate calibration, but currently if we cut out any stages, we get
%inadequate performance. We're working on it though.

\begin{srefaq}{Why is \prog{cmcalibrate} so slow?} The
    necessity of doing 8 separate exponential tail fitting stages
    (see above), and the fact that CM search algorithms scale more
    than $LN^2$ with sequence length $L$ and model consensus length
    $N$ make the program excruciatingly slow. Notice that some of the
    8 stages are much faster than others. The two Inside stages usually
    take a large majority of the total run time. You might argue this
    means we shouldn't use Inside, but it's the most sensitive
    algorithm we have; and sensitivity trumps speed in our design
    goals.
\end{srefaq}

\subsection{Accuracy of E-values}

The E-values reported by \prog{cmsearch} are not extremely accurate.
This is because CM scores don't fit the exponential tail distribution
extremely well. Empirically, local alignment scores returned from
local searches fit exponential tails fairly well, and glocal alignment
scores fit less well. We will continue to work on making E-values more
accurate in future versions of \software{infernal}.

One important factor in the accuracy of E-values is the GC content of
the target database. This is because many CMs are biased towards
particular GC content (usually low GC), in many cases giving A-rich
sequence high scores simply due to their high composition of
As. \prog{cmsearch} partially alleviates the problem of biased
composition using a post-hoc correction called null3 (see ``Biased
composition filtering: the null3 model below''). However, the problem
still persists and is particularly evident when the target database
being searched has a very low (about 25\%) or very high (about 65\%)
GC content. \prog{cmcalibrate} calibrates the E-value statistics for a
genome composition of about 46\% GC (based on an average measure from
a sampling of genomes from the three domains of life). When a target
database with GC content lower than 46\% is searched, the effect is
that there are usually more high scoring hits than the calibrated CM
expects, and lower E-values for random hits can result (that is you
might observe 5-25 hits with an E-value less than 1 for
example). Conversely, when a target database with GC content above
46\% is searched, the effect is the opposite, and higher E-values
often result (you might observe only 1-5 hits with an E-value less than
25). These effects are the average case, but different models will
give different results. We consider the E-values in \software{infernal} a
work in progress, so feel free to report examples of particularly bad
(or good) performance of E-values to us.

\subsection{In more detail: Rfam TC/NC/GA cutoffs}

When a Rfam model is built, the Rfam curation team keeps track of
scores of every hit in a large nonredundant database. They record
three types of score cutoffs on Rfam CM files:

\begin{wideitem}
\item[GA (gathering cutoff)]: the score used as cutoff in
constructing Rfam. All database hits that score at or above the 
GA bit score will be included in the Rfam ``full alignment''.

\item[TC (trusted cutoff)]: the scores of the lowest-scoring hit(s)
that were included as true member(s) of the Rfam family. Hits above
the TC score are ``within'' the Rfam family and almost certainly
members.

\item[NC (noise cutoff)]: the score of the highest-scoring hit(s) that
were \textit{not} included as true members of the Rfam family, because
they were considered to be the top of the noise.  Hits above the NC
cutoff are above the top scoring noise in the Rfam NR database search,
so are likely homologues, but not as trustworthy as hits over the GA
or TC cutoffs.
\end{wideitem}

In order of increasing conservativeness, the cutoffs rank: NC, GA, and
TC.

The GA cutoff, being the actual cutoff used in constructing Rfam,
are a very good choice to use to collate large-scale automated data,
like counting RNA family members in a sequenced genome.

The TC and NC cutoffs are less useful, and only really there as
documentation of Rfam construction. In general, the TC cutoff would
be a extremely conservative cutoff to use in a database search, more
conservative than GA. The NC cutoff is less conservative than GA.

Why use GA (or the other cutoffs) instead of the E-value? Rfam
artificially imposes a ``flat'', nonhierarchical structure on RNA
sequence space.  Rfam asserts that no Rfam family is related to any
other Rfam family. This is obvious nonsense: many Rfam families are in
fact homologous.  The different SRP families are one example; the
different RNaseP families are another. \software{infernal} often
detect significant relationships between families that Rfam chooses to
suppress. In these cases, the Rfam GA cutoff will be elevated to
artifically separate two homologous but distantly related subgroups of
the same structural superfamily.

\begin{srefaq}{Why isn't sequence X included in a Rfam full alignment?
It has a significant score!} For the reasons above, the sequences in
Rfam full alignments are harvested using curated GA thresholds, rather
than using score or E-value thresholds. Please don't go writing a
paper that claims CMs don't detect some similarity until you've done
the experiment with CMs (and E-values) instead of just looking at
curated Rfam classifications.
\end{srefaq}

The mechanism that \software{infernal} uses to incorporate up these cutoffs is
general: Stockholm format multiple sequence alignments can carry
appropriate TC, NC, and GA markup lines. This means that you can use a
Rfam-like cutoff system if you like, just by adding the appropriate
Stockholm markup to your collection of alignments. When these numbers
are available in the CM, \prog{cmsearch} provides options
for setting search cutoffs to GA, TC, or NC automatically (these options
are \prog{--ga, --tc} and \prog{--nc}).

\subsubsection{Predicting running times for searches with Rfam cutoffs}
The next section explains how \prog{cmcalibrate} determines HMM filter
thresholds to use to accelerate \prog{cmsearch}. These filter
thresholds are dependent on the final threshold used in
\prog{cmsearch}, in general, the stricter the final threshold the
stricter the filter threshold and the greater the acceleration from
the filter. Because the Rfam GA/NC/TC cutoffs are relatively strict it
is often possible to achieve large speedups of up to 100-fold or more
when they're used as the final threshold. Section 6 explains this in
more detail, and shows an example of predicting the running time of
filtered searches with Rfam cutoffs using the \prog{cmstat} program.

\subsection{Biased composition filtering: the null3 model}

I've lied. \software{infernal} bit scores are actually calculated as
log odds scores relative to \emph{two} null hypotheses. The first is the null model
built into the CM when it was built with \prog{cmbuild}.
The second, called \emph{null3}, is an \emph{ad hoc} model calculated
on the fly for each alignment, from the characteristics of that
alignment. (Why null3? To differentiate it from the null2 model used
by the \software{HMMER} software package). The purpose of null3 is to
compensate for false positive hits caused by simple biased composition
regions in the target sequence.

Common biased composition filters like XNU, DUST, and SEG are
qualitative filters -- if a region is detected as biased composition,
it is masked (the residues are converted to X's).  The
\software{infernal} composition filter is a quantitative filter, that
tests whether the sequence is a better match to the CM, the
null (random composition) model, or a null3 model of biased nucleotide
composition.

This is a Good Thing, but on the other hand, the null3 model is not
very sophisticated. It is a single-state HMM just like the main null
model, which means it only captures residue composition, like DUST; no
attempt is made in \software{infernal} to filter short-period repetitive sequences
like the XNU algorithm does. 

The null3 model was motivated by the observation that many
high-scoring false positive hits in \prog{cmsearch} are to regions of
the target database with with highly biased residue composition, in
particular regions with high percentages of A and U residues. The
first null model used by \software{infernal} is by default 25\% A, C,
G, and U (this model can be changed with the \prog{--null} option to
\prog{cmbuild}). If a model has a bias for a particular residue, for
example A,  and a target regions is composed of an overrepresentation
of that residue then it will receive a high score simply because it is
A-rich. 


A different null3 model is calculated for every alignment. The 4
emission probabilities of the null3 model are calculated as 
simply their occurence within the region of the hit. For example, if
the hit is 50 residues long and contains $20$ As, $5$ Cs, $5$ Gs and $20$ Us,
then the null3 model probabilitiles will be calculated as $(0.4, 0.1,
0.1, 0.4)$. 

But now we've got \emph{two} null hypotheses. We said we report a bit
score that's a log-odds ratio of our model likelihood and \emph{one}
null hypothesis likelihood. How do we calculate a score if we have
more than one null hypothesis? \software{infernal} does a bit of algebraic sleight
of hand here, to arrive at an additive correction to the original
score that it calls the ``null3 score correction''. 

\subsubsection{derivation of the null3 score correction}

We arrived at the parameters of the null3 model in a very \emph{ad
hoc} way. However, after that, the way \software{infernal} arrives at the final bit
score once the null3 parameters have been determined is clean
(e.g. derivable) Bayesian probability theory. It is analagous to the
way \software{HMMER} uses the \emph{null2} score correction.

If we take the Bayesian view, we're interested in the probability of a
hypothesis $H$ given some observed data $D$:

\[
   P(H | D) = \frac{P(D | H) P(H)}{\sum_{H_i} P(D | H_i) P(H_i)},
\]

an equation which forces us to state explicit probabilistic models not
just for the hypothesis we want to test, but also for the alternative
hypotheses we want to test against. Up until now, we've considered two
hypotheses for an observed sequence $D$: either it came from our
CM (call that model $M$), or it came from our null hypothesis
for random, unrelated sequences (call that model $N$). If these are
the only two models we consider, the Bayesian posterior for the model
$M$ is:

\[
   P(M | D) = \frac{P(D | M) P(M)}{P(D | M) P(M) + P(D | N) P(N)}
\]

Recall that the log odds score reported by \software{infernal}'s alignment
algorithms is

\[
  s = \log \frac{P(D | M)}{P(D | N)}.
\]

Let's assume for simplicity that \emph{a priori}, the profile and the
null model are equiprobable, so the priors $P(M)$ and $P(N)$
cancel. Then the log odds score $s$ is related to the Bayesian
posterior by a sigmoid function,

\[
  P(M | D) = \frac{e^s}{e^s + 1}.
\]

(We don't have to assume that the two hypotheses are equiprobable;
keeping these around would just add an extra $\pi = \log P(M) / P(N)$
factor to $s$. We'll reintroduce these prior log odds scores $\pi$
shortly.)

The simple sigmoid relationship between the posterior and the log odds
score suggests a plausible basis for calculating a score that includes
contributions of more than one null hypothesis: \textbf{we desire a
generalized score $S$ such that:}

\[
  \frac{e^S}{e^S + 1} = P(M | D),
\]

\textbf{for \emph{any} number of alternative hypotheses under consideration.}

So, let $N_i$ represent any number of alternative null models
$N_i$. Then, by algebraic rearrangement of Bayes' theorem,

\[
   S = \log \frac{P(S | M) P(M)}{ \sum_{i} P(S | N_i) P(N_i)}. 
\]

We saw above that \software{infernal} internally calculates a log odds score $s$, of
the model relative to the first null hypothesis. Let's now call that
$s_M$, the alignment score of the model. \software{infernal} extends that same
scoring system to all additional competing hypotheses, calculating a
log odds score relative to the first null hypothesis for any
additional null hypotheses $i > 1$:

\[
  s_i = \log \frac{P(D | N_i)}{P(D | N_1)}
\]

We can also state prior scores $\pi_i$ for how relatively likely
each null hypothesis is, relative to the main one:

\[
  \pi_i = \log \frac{P(N_i)}{P(N_1)}
\]

(Remember that we assumed $\pi_M = 0$; but we're going to put it back
in anyway now.)

Now we can express $S$ in terms of the internal scores $s$ and
prior scores $\pi$:

\[
   S = \log  \frac{e^{s_M + \pi_M}} { 1 + \sum_{i>1} e^{s_i + \pi_i}},
\]

which therefore simply amounts to an additive correction of the
original score, $(s_M + \pi_M)$:

\[
  S = (s_M + \pi_M) - \log \left( 1 + \sum_{i>1} e^{s_i + \pi_i} \right)
\]

So, to calculate its reported score, \software{infernal} uses four quantities:

\begin{enumerate}
\item [$s_M$] The (simple, uncorrected) log odds score for the model,
calculated by optimal alignment of the model to the sequence.

\item [$\pi_M$] The log odds of the priors, $\log P(M)/P(N_1)$. \software{infernal}
   implicitly assumes this factor to be 0.

\item [$s_2$] The (simple, uncorrected) log odds score
   for the null3 hypothesis, calculated by rescoring the residues
   of the alignment under the null3 model.

\item [$\pi_2$] The log odds of the priors, $\log P(N_2)/P(N_1)$. 
\software{infernal} arbitrarily assumes that the null3 model is
$\frac{1}{32}$ as likely as the main null model, so this factor
is -5 bits.
\end{enumerate}

The code that calculates the null3 correction is in 
\prog{cm\_parsetree.c:ScoreCorrectionNull3()}.

The null3 correction is usually close to zero, for random sequences,
but becomes a significant quantitative penalty on biased composition
sequences.  It gets added to the original alignment score to form
\software{infernal}'s final bit score.

The null3 score correction is introduced in version 1.0 and was not
present in any of the 0.x versions of \software{infernal}. This can
lead to large differences in the scores reported by 1.0 and previous
versions. 

The following table shows the penalty for a $100$ nucleotide hit with
varying compositions of A, C, G, and U residues. This table is included to give you
an idea of how severe the null3 correction is, and can be useful for
comparing bit scores from \software{infernal} 1.0 to previous
versions (which did not use the null3 correction). These are just a
sample of the possible composition of hits you might see. Again, these
scores are for $100$ nucleotide hits, to determine the correction for
a hit of length $x$ simply multiply the corresponding correction below
by $x/100$. For example, a $35$\% A, $15$\% C, $15$\% G, $35$\% U hit
of length $100$ nt would receive a $6.88$ bit penalty from
null3 (row 4). A $200$ nt hit of the same composition would
receive a penalty of $13.76$ bits. A $50$ nt hit of the same
composition would receive a $3.44$ bit penalty.

\vspace{0.5in}

\begin{center}
\begin{tabular}{r|rrrr|c}
      &        &        &        &        & NULL3 \\ 
  GC\%&    A\% &   C\%  &   G\%  &    U\% & correction (bits)  \\ \hline
  0.0 &   50.0 &    0.0 &    0.0 &   50.0 &              95.00 \\
 10.0 &   45.0 &    5.0 &    5.0 &   45.0 &              48.10 \\
 20.0 &   40.0 &   10.0 &   10.0 &   40.0 &              22.81 \\
 30.0 &   35.0 &   15.0 &   15.0 &   35.0 &               6.88 \\
 35.0 &   32.5 &   17.5 &   17.5 &   32.5 &               2.01 \\
 40.0 &   30.0 &   20.0 &   20.0 &   30.0 &               0.30 \\
 45.0 &   27.5 &   22.5 &   22.5 &   27.5 &               0.07 \\
 50.0 &   25.0 &   25.0 &   25.0 &   25.0 &               0.04 \\
 55.0 &   22.5 &   27.5 &   27.5 &   22.5 &               0.07 \\
 60.0 &   20.0 &   30.0 &   30.0 &   20.0 &               0.30 \\
 65.0 &   17.5 &   32.5 &   32.5 &   17.5 &               2.01 \\
 70.0 &   15.0 &   35.0 &   35.0 &   15.0 &               6.88 \\
 80.0 &   10.0 &   40.0 &   40.0 &   10.0 &              22.81 \\
 90.0 &    5.0 &   45.0 &   45.0 &    5.0 &              48.10 \\
100.0 &    0.0 &   50.0 &   50.0 &    0.0 &              95.00 \\

\end{tabular}
\end{center}

\vspace{0.5in}


% obtained using esl-null3 a specialized easel miniapp
% created basically solely to make this table. 
% A frozen copy of the version used to make this table
% (with -l option)  
% is : /groups/eddy/home/nawrockie/infernal/easel/miniapps/bkups/8_0619-1/esl-null3
%
% raw output:
% > esl-null3 -l 
%   GC      A      C      G      U  correction (bits)
%-----  -----  -----  -----  -----  -----------------
%100.0    0.0   50.0   50.0    0.0              95.00
% 90.0    5.0   45.0   45.0    5.0              48.10
% 80.0   10.0   40.0   40.0   10.0              22.81
% 70.0   15.0   35.0   35.0   15.0               6.88
% 65.0   17.5   32.5   32.5   17.5               2.01
% 60.0   20.0   30.0   30.0   20.0               0.30
% 55.0   22.5   27.5   27.5   22.5               0.07
% 50.0   25.0   25.0   25.0   25.0               0.04
% 45.0   27.5   22.5   22.5   27.5               0.07
% 40.0   30.0   20.0   20.0   30.0               0.30
% 35.0   32.5   17.5   17.5   32.5               2.01
% 30.0   35.0   15.0   15.0   35.0               6.88
% 20.0   40.0   10.0   10.0   40.0              22.81
% 10.0   45.0    5.0    5.0   45.0              48.10
%  0.0   50.0    0.0    0.0   50.0              95.00

By default, the null3 score correction is used by \prog{cmcalibrate,
cmsearch} and \prog{cmalign}. It can be turned off in any of these
programs by using the \prog{--no-null3} option (which can only be seen
in the list of options if \prog{--devhelp} is invoked)). However, be careful,
the E-values for models that are calibrated with \prog{--no-null3} are
only valid when \prog{--no-null3} is also used with
\prog{cmsearch}. Likewise, if \prog{--no-null3} is \emph{not} used
during calibration, it should not be used during search.


